{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Notebook\n",
    "\n",
    "The purpose of this notebook is to process and aggregate the *.csv* files provided by `twitch_stream_bot.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "processing_old_twitch_API = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the *.csv* files are located in the `sync` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 29 duplicates\n",
      "Deleting duplicates...\n",
      "There are 0 duplicates\n"
     ]
    }
   ],
   "source": [
    "if processing_old_twitch_API:\n",
    "    csv_path = './sync/tagIds/' # For old Twitch API\n",
    "else:\n",
    "    csv_path = './sync/tagIds_tags/' # For new Twitch API\n",
    "\n",
    "csv_dfs = [pd.read_csv(csv_path + file) for file in os.listdir(path=csv_path) if file.endswith('csv')]\n",
    "\n",
    "df = pd.concat(csv_dfs, ignore_index=True)\n",
    "\n",
    "print(f'There are {len(df) - len(df.id.drop_duplicates())} duplicates')\n",
    "\n",
    "print('Deleting duplicates...')\n",
    "df.sort_values('_custom_ended_at', inplace=True)\n",
    "df = df.groupby(['id']).apply(lambda df_ : df_.iloc[-1]).reset_index(drop=True)\n",
    "\n",
    "print(f'There are {len(df) - len(df.id.drop_duplicates())} duplicates')\n",
    "\n",
    "df.sort_values('started_at', inplace=True, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing some infos about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1725 streams\n",
      "711 different broadcasters\n",
      "first started live : 2023-01-05T13:18:16Z\n",
      "last started live : nan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''{len(df)} streams\n",
    "{len(df.groupby('user_id'))} different broadcasters\n",
    "first started live : {df.iloc[0]['started_at']}\n",
    "last started live : {df.iloc[-1]['started_at']}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the dataframe in the `../Data` folder for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if processing_old_twitch_API:\n",
    "    df.to_csv('../Data/twitch_streams_vtuber_tagIds.csv', index=False)\n",
    "else:\n",
    "    df.to_csv('../Data/twitch_streams_vtuber_tagIds_tags.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d24ac629bf112d802257883b8c110d3748261c81a2230e5825f87b9855adaaa8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
